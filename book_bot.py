
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from openai import OpenAI
import config
from book_embedder import BookEmbedder
from book_details import BookDetailsLoader
from collections import defaultdict
from datetime import datetime, timedelta
import re


last_shown_results = defaultdict(list)  # âœ… Separate for tracking display
openai_client = OpenAI(api_key=config.OPENAI_API_KEY)
embedder = None
book_details_loader = None
conversation_memory = defaultdict(list)
search_results_memory = defaultdict(list)
last_message_time = defaultdict(lambda: datetime.now())
last_query_memory = defaultdict(str)

ORIGINAL_EXCEL_PATH = "output/final_normalize.xlsx"

config.SYSTEM_PROMPT = """
Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ Ù‡Ø³ØªÛŒØ¯.
**Ù‚ÙˆØ§Ù†ÛŒÙ† Ù…Ù‡Ù…:**
1. **ÙÙ‚Ø· Ø§Ø² Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯**
2. **Ù†Ø­ÙˆÙ‡ Ù¾Ø§Ø³Ø®:**
   a) Ø¬Ø³ØªØ¬ÙˆÛŒ Ø§ÙˆÙ„ÛŒÙ‡: ØªÙ…Ø§Ù… Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯
   b) Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨ÛŒØ´ØªØ±: ÙÙ‚Ø· Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
   c) Ø³ÙˆØ§Ù„ Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ú©Ù†ÛŒØ¯
   d) Ø³ÙˆØ§Ù„ ØªÙˆØ¶ÛŒØ­ÛŒ: ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡ÛŒØ¯
3. **ÙØ±Ù…Øª:**
   ğŸ”¹ Â«Ø¹Ù†ÙˆØ§Ù†Â»
   Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡: ...
   Ù†Ø§Ø´Ø±: ...
   (Ùˆ Ø¨Ù‚ÛŒÙ‡)
4. **Ø²Ø¨Ø§Ù†**: ÙØ§Ø±Ø³ÛŒØŒ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ØŒ Ù…Ø®ØªØµØ±
5. **Ù…Ù…Ù†ÙˆØ¹ÛŒØªâ€ŒÙ‡Ø§:**
   - "Ú©ØªØ§Ø¨ÛŒ Ù†Ø¯Ø§Ø±ÛŒÙ…" Ù†Ú¯Ùˆ
   - Ú©ØªØ§Ø¨ ØªÚ©Ø±Ø§Ø±ÛŒ Ù…Ø¹Ø±ÙÛŒ Ù†Ú©Ù†
"""

def format_cutter(cutter_raw):
    if not cutter_raw or str(cutter_raw).lower() in ['nan', 'none', '']:
        return "Ù†Ø§Ù…Ø´Ø®Øµ"
    cutter = str(cutter_raw).strip()
    if cutter.endswith('/'):
        cutter = cutter[:-1]
    return cutter

def format_location(location_raw):
    if not location_raw or str(location_raw).lower() in ['nan', 'none', '']:
        return "Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù…Ø±Ú©Ø²ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ"
    return str(location_raw).strip()

def enrich_search_result(result):
    if book_details_loader is None:
        return result
    row_id = result.get('Ø±Ø¯ÙŠÙ')
    if not row_id:
        return result
    details = book_details_loader.get_book_details(row_id)
    if details:
        enriched = result.copy()
        enriched.update(details)
        return enriched
    return result


def clean_old_conversations():
    current_time = datetime.now()
    expired_chats = []
    for chat_id, last_time in last_message_time.items():
        if current_time - last_time > timedelta(days=7):
            expired_chats.append(chat_id)
    for chat_id in expired_chats:
        conversation_memory.pop(chat_id, None)
        search_results_memory.pop(chat_id, None)
        last_message_time.pop(chat_id, None)
        last_query_memory.pop(chat_id, None)
        last_shown_results.pop(chat_id, None)
    if expired_chats:
        print(f"ğŸ—‘ï¸ Cleaned: {len(expired_chats)} old conversations")


def add_to_conversation(chat_id, role, content):
    conversation_memory[chat_id].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now()
    })
    current_time = datetime.now()
    three_days_ago = current_time - timedelta(days=3)
    conversation_memory[chat_id] = [
        msg for msg in conversation_memory[chat_id]
        if msg["timestamp"] > three_days_ago
    ]
    if len(conversation_memory[chat_id]) > 100:
        conversation_memory[chat_id] = conversation_memory[chat_id][-100:]
    last_message_time[chat_id] = datetime.now()


def get_conversation_history(chat_id, limit=20):
    if chat_id not in conversation_memory:
        return []
    current_time = datetime.now()
    three_days_ago = current_time - timedelta(days=3)
    recent_messages = [
        msg for msg in conversation_memory[chat_id]
        if msg["timestamp"] > three_days_ago
    ]
    return recent_messages[-limit:]


def save_search_results(chat_id, results, query=""):
    search_results_memory[chat_id] = results
    if query:
        last_query_memory[chat_id] = query
    last_message_time[chat_id] = datetime.now()


def get_last_search_results(chat_id):
    return search_results_memory.get(chat_id, [])


def get_last_query(chat_id):
    return last_query_memory.get(chat_id, "")


def format_book_output(gpt_response, search_results):
    mentioned_titles = re.findall(r'[Â«"]([^Â»"]+)[Â»"]', gpt_response)

    if not mentioned_titles:
        mentioned_titles = [book.get('Ø¹Ù†ÙˆØ§Ù†', '') for book in search_results[:5]]

    def normalize_title(title):
        return re.sub(r'\s+', ' ', title.strip())

    mentioned_titles_norm = [normalize_title(t) for t in mentioned_titles]

    formatted_books = []
    used_indices = set()

    for title_norm in mentioned_titles_norm:
        for idx, book in enumerate(search_results):
            if idx in used_indices:
                continue

            book_title_norm = normalize_title(book.get('Ø¹Ù†ÙˆØ§Ù†', ''))

            if title_norm in book_title_norm or book_title_norm in title_norm or title_norm == book_title_norm:
                book_formatted = f"""ğŸ”¹ Â«{book['Ø¹Ù†ÙˆØ§Ù†']}Â»
   Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡: {book.get('Ù¾Ø¯ÙŠØ¯Ø¢ÙˆØ±Ù†Ø¯Ù‡', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
   Ù†Ø§Ø´Ø±: {book.get('Ù†Ø§Ø´Ø±', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
   Ø³Ø§Ù„ Ø§Ù†ØªØ´Ø§Ø±: {book.get('ØªØ§Ø±ÙŠØ® Ù†Ø´Ø±', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
   Ø´Ù…Ø§Ø±Ù‡ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ: {book.get('Ø´Ù…Ø§Ø±Ù‡_Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
   Ù…Ø­Ù„ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ: {book.get('Ù…Ø­Ù„_Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ', 'Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù…Ø±Ú©Ø²ÛŒ')}
   Ù…ÙˆØ¶ÙˆØ¹: {book.get('Ù…ÙˆØ¶ÙˆØ¹', 'Ù†Ø§Ù…Ø´Ø®Øµ')}"""

                formatted_books.append(book_formatted)
                used_indices.add(idx)
                break

    if not formatted_books:
        for book in search_results[:5]:
            book_formatted = f"""ğŸ”¹ Â«{book['Ø¹Ù†ÙˆØ§Ù†']}Â»
   Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡: {book.get('Ù¾Ø¯ÙŠØ¯Ø¢ÙˆØ±Ù†Ø¯Ù‡', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
   Ù†Ø§Ø´Ø±: {book.get('Ù†Ø§Ø´Ø±', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
   Ø³Ø§Ù„ Ø§Ù†ØªØ´Ø§Ø±: {book.get('ØªØ§Ø±ÙŠØ® Ù†Ø´Ø±', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
   Ø´Ù…Ø§Ø±Ù‡ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ: {book.get('Ø´Ù…Ø§Ø±Ù‡_Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
   Ù…Ø­Ù„ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ: {book.get('Ù…Ø­Ù„_Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ', 'Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù…Ø±Ú©Ø²ÛŒ')}
   Ù…ÙˆØ¶ÙˆØ¹: {book.get('Ù…ÙˆØ¶ÙˆØ¹', 'Ù†Ø§Ù…Ø´Ø®Øµ')}"""
            formatted_books.append(book_formatted)

    gpt_text_lines = []
    for line in gpt_response.split('\n'):
        line = line.strip()
        if line.startswith('Â«') or line.startswith('Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡:') or line.startswith('Ù†Ø§Ø´Ø±:') or line.startswith('Ø³Ø§Ù„:') or line.startswith('Ù…ÙˆØ¶ÙˆØ¹:'):
            continue
        if line and len(line) > 3:
            gpt_text_lines.append(line)

    gpt_text_only = '\n'.join(gpt_text_lines)

    final_output = ""
    if gpt_text_only and len(gpt_text_only) > 20:
        final_output += gpt_text_only.strip() + "\n\n"

    final_output += "\n\n".join(formatted_books)

    return final_output


# RAG helper functions
def initialize_embedder():
    global embedder, book_details_loader
    print("ğŸ”„ Loading FAISS index...")
    try:
        embedder = BookEmbedder(api_key=config.OPENAI_API_KEY)
        embedder.load_index(config.FAISS_INDEX_PATH)
        print("âœ… FAISS index loaded")
    except Exception as e:
        print(f"âŒ Error loading index: {e}")
        return False
    print("ğŸ”„ Loading book details...")
    try:
        book_details_loader = BookDetailsLoader(ORIGINAL_EXCEL_PATH)
        print("âœ… Book details loaded")
    except Exception as e:
        print(f"âŒ Error loading details: {e}")
        return False
    return True


def is_followup_question(query, chat_id):
    followup_keywords = [
        'Ø¨Ù„Ù‡', 'Ø¢Ø±Ù‡', 'Ø§ÙˆÚ©ÛŒ', 'Ø¨Ø§Ø´Ù‡', 'Ø¨ÛŒØ´ØªØ±', 'Ø¬Ø¯ÛŒØ¯ØªØ±', 'Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±',
        'Ù…Ø¨ØªØ¯ÛŒ', 'Ù¾ÛŒØ´Ø±ÙØªÙ‡', 'Ø³Ø§Ø¯Ù‡', 'Ø³Ø®Øª', 'Ø¨Ù‡ØªØ±ÛŒÙ†', 'Ú©Ø¯ÙˆÙ…', 'Ú©Ø¯Ø§Ù…',
        'Ø§ÙˆÙ„ÛŒ', 'Ø¯ÙˆÙ…ÛŒ', 'Ø§ÙˆÙ†', 'Ø§ÛŒÙ†', 'Ù‡Ù…ÙˆÙ†', 'Ù‡Ù…ÛŒÙ†', 'Ø¨Ø§Ø²', 'Ø¯ÙˆØ¨Ø§Ø±Ù‡',
        'Ú†Ù†Ø¯ ØªØ§ Ø¯ÛŒÚ¯Ù‡', 'Ú†Ù†Ø¯ØªØ§ Ø¯ÛŒÚ¯Ù‡', 'ØªØ§ Ø¯ÛŒÚ¯Ù‡', 'Ù…Ø¹Ø±ÙÛŒ Ú©Ù†', 'Ù†Ø´ÙˆÙ† Ø¨Ø¯Ù‡',
        'Ø¨Ú¯Ùˆ', 'ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡', 'Ú†Ø·ÙˆØ±Ù‡', 'Ø±Ø§Ø¬Ø¹', 'Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø§ÙˆÙ†', 'Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø§ÛŒÙ†',
        'Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù…', 'Ø¯ÙˆØ³ Ø¯Ø§Ø±Ù…', 'Ø¹Ø§Ù„ÛŒ Ø¨ÙˆØ¯', 'Ø¨Ù‡ØªØ±ÛŒÙ†', 'Ø§Ø²Ø´', 'Ø§Ø² Ø§ÙˆÙ†',
        'Ø¨ÛŒØ´ØªØ± Ø§Ø²', 'Ø¬Ø²Ø¦ÛŒØ§Øª', 'Ø®Ù„Ø§ØµÙ‡', 'ØªÙˆØ¶ÛŒØ­', 'Ú†Ø±Ø§', 'Ú†Ø·ÙˆØ±', 'Ù…Ø«Ø§Ù„',
        'Ø´Ø¨ÛŒÙ‡', 'Ù…Ø´Ø§Ø¨Ù‡', 'Ú©ØªØ§Ø¨ Ø¯ÙˆÙ…', 'Ú©ØªØ§Ø¨ Ø¢Ø®Ø±', 'Ø´Ø±Ø­ Ø¨Ø¯Ù‡', 'Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ú©ØªØ§Ø¨',
        'Ø¨ÛŒØ´ØªØ± Ø´Ø±Ø­', 'Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ø¢Ø®Ø±', 'Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ú©ØªØ§Ø¨ Ø¢Ø®Ø±', 'Ø§ÛŒÙ† Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ú©ÛŒÙ‡'
    ]
    query_lower = query.lower()
    has_followup_keyword = any(keyword in query_lower for keyword in followup_keywords)
    has_previous_results = len(get_last_search_results(chat_id)) > 0
    if has_followup_keyword and has_previous_results and len(query.split()) <= 10:
        return True
    new_search_indicators = ['Ú©ØªØ§Ø¨', 'Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡', 'Ø´Ø¹Ø±', 'Ø¯Ø§Ø³ØªØ§Ù†', 'Ø±Ù…Ø§Ù†']
    if any(indicator in query_lower for indicator in new_search_indicators):
        if has_followup_keyword and ('Ø¯ÛŒÚ¯Ù‡' in query_lower or 'Ø¯ÛŒÚ¯Ø±' in query_lower or 'Ø¨Ø§Ø²' in query_lower):
            return True
        else:
            return False
    return has_followup_keyword and has_previous_results


def filter_results_with_gpt(user_query, search_results, original_query=""):
    if not search_results:
        return []
    books_list = []
    for i, r in enumerate(search_results, 1):
        books_list.append(f"{i}. Â«{r['Ø¹Ù†ÙˆØ§Ù†']}Â» - Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡: {r['Ù¾Ø¯ÙŠØ¯Ø¢ÙˆØ±Ù†Ø¯Ù‡']}, Ù…ÙˆØ¶ÙˆØ¹: {r['Ù…ÙˆØ¶ÙˆØ¹']}")
    books_text = "\n".join(books_list)
    filter_prompt = f"""
Ø³ÙˆØ§Ù„: "{user_query}"
Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ: "{original_query}"

Ù„ÛŒØ³Øª Ú©ØªØ§Ø¨â€ŒÙ‡Ø§:
{books_text}

ÙÙ‚Ø· Ù…Ø±ØªØ¨Ø·â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†.
Ø®Ø±ÙˆØ¬ÛŒ: Ø´Ù…Ø§Ø±Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ú©Ø§Ù…Ø§ (Ù…Ø«Ù„ '1,3') ÛŒØ§ 'Ù‡ÛŒÚ†Ú©Ø¯Ø§Ù…'.
"""
    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": filter_prompt}],
            max_tokens=100,
            temperature=0.1
        )
        answer = response.choices[0].message.content.strip()
        if "Ù‡ÛŒÚ†Ú©Ø¯Ø§Ù…" in answer.lower():
            return []
        numbers = re.findall(r'\b\d+\b', answer)
        numbers = [int(n) for n in numbers if 1 <= int(n) <= len(search_results)]
        filtered = [search_results[n-1] for n in set(numbers)]
        print(f"ğŸ” GPT Filter: {len(filtered)}/{len(search_results)} Ù…Ø±ØªØ¨Ø·")
        if len(filtered) < 2 and len(search_results) >= 2:
            return search_results[:5]
        return filtered
    except Exception as e:
        print(f"âš ï¸ Error in filter: {e}")
        return search_results[:5]


def search_books(query, k=None, distance_threshold=0.8, exclude_rows=None):
    if embedder is None:
        return []
    try:
        results = embedder.search(query, k=k or 30)
        enriched_results = []
        for r in results:
            enriched = enrich_search_result(r)
            if enriched['distance'] < distance_threshold:
                if exclude_rows is None or enriched['Ø±Ø¯ÙŠÙ'] not in exclude_rows:
                    enriched_results.append(enriched)
        print(f"ğŸ“Š Search: '{query[:50]}...' â†’ Result: {len(enriched_results)} ")
        return enriched_results[:k] if k else enriched_results[:10]
    except Exception as e:
        print(f"âŒ Error in search: {e}")
        return []


def generate_rag_response(user_query, chat_id):
    clean_old_conversations()

    # Greeting
    greetings = ['Ø³Ù„Ø§Ù…', 'Ø¯Ø±ÙˆØ¯', 'ØµØ¨Ø­ Ø¨Ø®ÛŒØ±', 'Ø¹ØµØ± Ø¨Ø®ÛŒØ±', 'Ø´Ø¨ Ø¨Ø®ÛŒØ±', 'Ø®ÙˆØ¨ÛŒ', 'Ú†Ø·ÙˆØ±ÛŒ', 'Ø­Ø§Ù„Øª', 'hello', 'hi']
    if any(greet in user_query.lower() for greet in greetings) and len(user_query.split()) <= 3:
        return "Ø³Ù„Ø§Ù…! ğŸ‘‹\n\nÚ†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ú©Ù…Ú©ØªÙˆÙ† Ú©Ù†Ù…ØŸ\nÙ…Ø«Ø§Ù„: Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ù†ÛŒÙ…Ø§ ÛŒÙˆØ´ÛŒØ¬"

    is_followup = is_followup_question(user_query, chat_id)
    query_lower = user_query.lower()

    # âœ… FIX 2: Detect author
    asking_author_patterns = [
        r'Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡\s+(Ú©ØªØ§Ø¨\s+)?(Ø§ÙˆÙ„|Ø¯ÙˆÙ…|Ø³ÙˆÙ…|Ú†Ù‡Ø§Ø±Ù…|Ù¾Ù†Ø¬Ù…|Ø¢Ø®Ø±|Ø§Ø®Ø±|Û±|Û²|Û³|Û´|Ûµ|1|2|3|4|5)ÛŒ?\s*(Ú©ÛŒÙ‡|Ú†ÛŒÙ‡|Ø§Ø³Øª|Ù‡Ø³Øª)?',
        r'(Ø§ÙˆÙ„|Ø¯ÙˆÙ…|Ø³ÙˆÙ…|Ú†Ù‡Ø§Ø±Ù…|Ù¾Ù†Ø¬Ù…|Ø¢Ø®Ø±|Ø§Ø®Ø±|Û±|Û²|Û³|Û´|Ûµ|1|2|3|4|5)ÛŒ?\s+Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡\s*Ø§Ø´?\s*(Ú©ÛŒÙ‡|Ú†ÛŒÙ‡)?',
    ]

    only_asking_author_name = (
        any(re.search(pattern, query_lower) for pattern in asking_author_patterns) and
        'Ù…Ø¹Ø±ÙÛŒ' not in query_lower and
        'Ø¨ÛŒØ´ØªØ±' not in query_lower and
        'Ø¯ÛŒÚ¯Ù‡' not in query_lower and
        'Ø¯ÛŒÚ¯Ø±' not in query_lower
    )

    if only_asking_author_name:
        print("\n" + "="*60)
        print("ğŸ“ Author's question")

        shown_results = last_shown_results.get(chat_id, [])

        print(f"ğŸ“‹ Counts: {len(shown_results)}")
        for i, book in enumerate(shown_results, 1):
            print(f"   {i}. Â«{book['Ø¹Ù†ÙˆØ§Ù†'][:40]}...Â»")

        if not shown_results:
            print("="*60 + "\n")
            return "Ù…ØªØ£Ø³ÙÙ…ØŒ Ù‡Ù†ÙˆØ² Ú©ØªØ§Ø¨ÛŒ Ù…Ø¹Ø±ÙÛŒ Ù†Ú©Ø±Ø¯Ù…."

        # âœ… FIX 2: Correct diagnosis index
        position = -1
        if 'Ø§ÙˆÙ„' in query_lower or 'Û±' in query_lower or '1' in query_lower:
            position = 0
        elif 'Ø¯ÙˆÙ…' in query_lower or 'Û²' in query_lower or '2' in query_lower:
            position = 1
        elif 'Ø³ÙˆÙ…' in query_lower or 'Û³' in query_lower or '3' in query_lower:
            position = 2
        elif 'Ú†Ù‡Ø§Ø±Ù…' in query_lower or 'Û´' in query_lower or '4' in query_lower:
            position = 3
        elif 'Ù¾Ù†Ø¬Ù…' in query_lower or 'Ûµ' in query_lower or '5' in query_lower:
            position = 4

        print(f"ğŸ¯ Index: {position}")

        if position >= 0 and position >= len(shown_results):
            print("="*60 + "\n")
            return f"Ù…ØªØ£Ø³ÙÙ…ØŒ Ù…Ù† ÙÙ‚Ø· {len(shown_results)} Ú©ØªØ§Ø¨ Ù…Ø¹Ø±ÙÛŒ Ú©Ø±Ø¯Ù…."

        target_book = shown_results[position]
        title = target_book['Ø¹Ù†ÙˆØ§Ù†']
        print(f"ğŸ“– Books: Â«{title[:50]}...Â»")

        author = target_book.get('Ù¾Ø¯ÙŠØ¯Ø¢ÙˆØ±Ù†Ø¯Ù‡', '').strip()
        author = re.sub(r'(Ù…ÙˆÙ„Ù|Ù†ÙˆØ´ØªÙ‡|ØªØ§Ù„ÛŒÙ|Ø§Ø²|ØªÙˆØ³Ø·)\s*', '', author, flags=re.IGNORECASE)
        author = re.sub(r'[/\.Ø›]', '', author)
        author = re.sub(r'\s+', ' ', author).strip()

        print(f"ğŸ‘¤ Author: {author}")
        print("="*60 + "\n")

        if not author or author.lower() in ['nan', 'none', '']:
            return f"Ù…ØªØ£Ø³ÙÙ…ØŒ Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ú©ØªØ§Ø¨ Â«{title}Â» Ø¯Ø± Ø³ÛŒØ³ØªÙ… Ø«Ø¨Øª Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª."

        return f"Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ú©ØªØ§Ø¨ Â«{title}Â»ØŒ Â«{author}Â» Ø§Ø³Øª."


    # Search for books by author
    author_search_keywords = [
        'Ø§Ø² Ø§ÛŒÙ† Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡', 'Ø§Ø² Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡', 'Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ø§ÛŒÙ†', 'Ú©ØªØ§Ø¨ Ù‡Ø§ÛŒ Ø§ÛŒÙ† Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡',
        'Ú©ØªØ§Ø¨ Ø¯ÛŒÚ¯Ù‡ Ø§Ø²', 'Ú©ØªØ§Ø¨ Ø§ÙˆÙ† Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡', 'Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ú©ØªØ§Ø¨ Ø§ÙˆÙ„', 'Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ú©ØªØ§Ø¨ Ø¯ÙˆÙ…',
        'Ú©ØªØ§Ø¨ Ù‡Ù…ÙˆÙ† Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡', 'Ø§Ø²Ø´ Ú©ØªØ§Ø¨', 'Ø§Ø² Ø§ÙˆÙ† Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡', 'Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ú©ØªØ§Ø¨ Ø¢Ø®Ø±',
        'Ø§Ø² Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ø¢Ø®Ø±', 'Ø§Ø² Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ø¯ÙˆÙ…', 'Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù… Ø§Ø² Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡', 'Ø¯ÙˆØ³ Ø¯Ø§Ø±Ù… Ø§Ø² Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡',
        'Ø§Ø² Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ú©ØªØ§Ø¨ Ø¯ÙˆÙ…', 'Ø§Ø² Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ú©ØªØ§Ø¨ Ø¢Ø®Ø±', 'Ú†Ù†Ø¯ØªØ§ Ú©ØªØ§Ø¨ Ø§Ø² Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡',
        'Ú©ØªØ§Ø¨ Ø¯ÛŒÚ¯Ù‡ Ø§ÛŒ Ø¯Ø§Ø±ÛŒÙ…', 'Ø§ÛŒÙ† Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ú©ÛŒÙ‡'
    ]

    author_search_done = False

    if is_followup and any(kw in query_lower for kw in author_search_keywords):
        print("ğŸ“š Author search request")

        prev_results = last_shown_results.get(chat_id, get_last_search_results(chat_id))

        if prev_results and len(prev_results) > 0:
            print(f"   ğŸ“‹ Count: {len(prev_results)}")

            # book selection
            if 'Ø§ÙˆÙ„' in query_lower or '1' in query_lower or 'Û±' in query_lower:
                target_book = prev_results[0]
            elif 'Ø¯ÙˆÙ…' in query_lower or '2' in query_lower or 'Û²' in query_lower:
                target_book = prev_results[1] if len(prev_results) > 1 else prev_results[0]
            elif 'Ø³ÙˆÙ…' in query_lower or '3' in query_lower or 'Û³' in query_lower:
                target_book = prev_results[2] if len(prev_results) > 2 else prev_results[0]
            elif 'Ø¢Ø®Ø±' in query_lower or 'Ø§Ø®Ø±' in query_lower or 'Ø¢Ø®Ø±ÛŒÙ†' in query_lower:
                target_book = prev_results[-1]
            else:
                target_book = prev_results[-1]

            print(f"   ğŸ“– Book: {target_book['Ø¹Ù†ÙˆØ§Ù†'][:40]}...")

            author_name = target_book.get('Ù¾Ø¯ÙŠØ¯Ø¢ÙˆØ±Ù†Ø¯Ù‡', '').strip()
            author_name = re.sub(r'(Ù…ÙˆÙ„Ù|Ù†ÙˆØ´ØªÙ‡|ØªØ§Ù„ÛŒÙ|Ø§Ø²|ØªÙˆØ³Ø·)\s*', '', author_name, flags=re.IGNORECASE)
            author_name = re.sub(r'[^\w\s,ØŒ]', ' ', author_name)
            author_name = re.sub(r'\s+', ' ', author_name).strip()

            if author_name.lower() in ['nan', 'none', ''] or not author_name:
                return "Ù…ØªØ£Ø³ÙÙ…ØŒ Ù†Ø§Ù… Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª."

            print(f"   ğŸ‘¤ Author: {author_name}")

            shown_results = last_shown_results.get(chat_id, [])
            previous_row_ids = [r['Ø±Ø¯ÙŠÙ'] for r in shown_results]

            search_results_raw = search_books(
                f"Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ø¯Ù‚ÛŒÙ‚: {author_name}",
                k=None,
                distance_threshold=1.2,
                exclude_rows=previous_row_ids
            )

            search_results = filter_results_with_gpt(
                f"Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ÛŒ {author_name}",
                search_results_raw,
                original_query=f"Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ÛŒ {author_name}"
            )

            if search_results and len(search_results) > 0:
                print(f"   âœ… {len(search_results)} Ú©ØªØ§Ø¨ Ø§Ø² Â«{author_name}Â»")
                save_search_results(chat_id, search_results, author_name)
                author_search_done = True
                is_followup = False
            else:
                return f"Ù…ØªØ£Ø³ÙÙ…ØŒ Ú©ØªØ§Ø¨ Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø² Â«{author_name}Â» Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯Ù…. ğŸ˜”"
        else:
            return "Ù…ØªØ£Ø³ÙÙ…ØŒ Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."

    if is_followup:
        print(f"ğŸ’¬ Follow-up detected")
        prev_results = get_last_search_results(chat_id)
        last_query = get_last_query(chat_id)

        if not prev_results:
            return "Ù…ØªØ£Ø³ÙÙ…ØŒ Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."

        explain_keywords = ['Ø´Ø±Ø­', 'ØªÙˆØ¶ÛŒØ­', 'Ø¯Ø±Ø¨Ø§Ø±Ù‡', 'Ø¬Ø²Ø¦ÛŒØ§Øª', 'Ø®Ù„Ø§ØµÙ‡', 'Ø¨ÛŒØ´ØªØ± Ø¨Ú¯Ùˆ', 'Ù…Ø¹Ø±ÙÛŒ Ú©Ù†']
        is_explain_question = any(kw in query_lower for kw in explain_keywords)

        if is_explain_question:
            print("ğŸ“– Explanation question identified")

            shown_results = last_shown_results.get(chat_id, [])

            if not shown_results:
                return "Ù…ØªØ£Ø³ÙÙ…ØŒ Ù‡Ù†ÙˆØ² Ú©ØªØ§Ø¨ÛŒ Ù…Ø¹Ø±ÙÛŒ Ù†Ú©Ø±Ø¯Ù…."

            selected_book = None
            if 'Ø§ÙˆÙ„' in query_lower or 'Û±' in query_lower or '1' in query_lower:
                selected_book = shown_results[0] if len(shown_results) > 0 else None
            elif 'Ø¯ÙˆÙ…' in query_lower or 'Û²' in query_lower or '2' in query_lower:
                selected_book = shown_results[1] if len(shown_results) > 1 else None
            elif 'Ø³ÙˆÙ…' in query_lower or 'Û³' in query_lower or '3' in query_lower:
                selected_book = shown_results[2] if len(shown_results) > 2 else None
            elif 'Ø¢Ø®Ø±' in query_lower or 'Ø§Ø®Ø±' in query_lower or 'Ø§ÛŒÙ†' in query_lower:
                selected_book = shown_results[-1]
            else:
                selected_book = shown_results[-1]

            if selected_book:
                title = selected_book['Ø¹Ù†ÙˆØ§Ù†']
                author = selected_book.get('Ù¾Ø¯ÙŠØ¯Ø¢ÙˆØ±Ù†Ø¯Ù‡', 'Ù†Ø§Ù…Ø´Ø®Øµ')
                publisher = selected_book.get('Ù†Ø§Ø´Ø±', 'Ù†Ø§Ù…Ø´Ø®Øµ')
                year = selected_book.get('ØªØ§Ø±ÙŠØ® Ù†Ø´Ø±', 'Ù†Ø§Ù…Ø´Ø®Øµ')
                subject = selected_book.get('Ù…ÙˆØ¶ÙˆØ¹', '')

                print(f"   ğŸ“– Ú©ØªØ§Ø¨: Â«{title[:40]}...Â»")

                single_context = (
                    f"Ø¹Ù†ÙˆØ§Ù†: Â«{title}Â»\n"
                    f"Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡: {author}\n"
                    f"Ù†Ø§Ø´Ø±: {publisher}\n"
                    f"Ø³Ø§Ù„: {year}\n"
                    f"Ù…ÙˆØ¶ÙˆØ¹: {subject}"
                )

                history = get_conversation_history(chat_id, limit=5)
                messages = [{"role": "system", "content": config.SYSTEM_PROMPT}]
                for h in history:
                    messages.append({"role": h["role"], "content": h["content"][:300]})

                user_message = (
                    f"Ú©ØªØ§Ø¨:\n{single_context}\n\n"
                    f"Ø³ÙˆØ§Ù„: {user_query}\n\n"
                    f"**Ø¯Ø³ØªÙˆØ±:** ÙÙ‚Ø· Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø§ÛŒÙ† Ú©ØªØ§Ø¨ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡. "
                    f"ÛŒÚ© Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…ÙÛŒØ¯ Ø¨Ù†ÙˆÛŒØ³ Ú©Ù‡ Ø§ÛŒÙ† Ú©ØªØ§Ø¨ Ú†ÛŒÙ‡ Ùˆ Ø¨Ø±Ø§ÛŒ Ú†Ù‡ Ú©Ø³Ø§Ù†ÛŒ Ù…Ù†Ø§Ø³Ø¨Ù‡."
                )
                messages.append({"role": "user", "content": user_message})

                try:
                    response = openai_client.chat.completions.create(
                        model=config.GPT_MODEL,
                        messages=messages,
                        max_tokens=500,
                        temperature=0.7
                    )
                    explanation = response.choices[0].message.content

                    add_to_conversation(chat_id, "user", user_query)
                    add_to_conversation(chat_id, "assistant", explanation)
                    return explanation

                except Exception as e:
                    print(f"âŒ Error in explanation: {e}")
                    return f"Ù…ØªØ£Ø³ÙÙ…ØŒ Ù†ØªÙˆØ§Ù†Ø³ØªÙ… Ø¯Ø±Ø¨Ø§Ø±Ù‡ Â«{title}Â» ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡Ù…."

        if any(word in query_lower for word in ['Ø¨ÛŒØ´ØªØ±', 'Ø¨Ø§Ø²', 'Ø¯ÙˆØ¨Ø§Ø±Ù‡', 'Ú†Ù†Ø¯ ØªØ§ Ø¯ÛŒÚ¯Ù‡', 'Ú†Ù†Ø¯ØªØ§ Ø¯ÛŒÚ¯Ù‡']):
            # âœ… FIX 1: exclude from last_shown_results (not search_results_memory)
            shown_results = last_shown_results.get(chat_id, [])
            previous_row_ids = [r['Ø±Ø¯ÙŠÙ'] for r in shown_results]

            print(f"ğŸ“ Count exclude: {len(previous_row_ids)}")
            print(f"ğŸš« IDs: {previous_row_ids[:5]}...")

            effective_query = last_query if last_query else query_lower
            effective_query = re.sub(r'\b(Ø¨Ø§Ø²|Ø¨ÛŒØ´ØªØ±|Ø¯ÙˆØ¨Ø§Ø±Ù‡|Ú†Ù†Ø¯ ØªØ§ Ø¯ÛŒÚ¯Ù‡|Ú†Ù†Ø¯ØªØ§ Ø¯ÛŒÚ¯Ù‡)\b', '', effective_query, flags=re.IGNORECASE).strip()

            if not effective_query:
                effective_query = last_query if last_query else "Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·"

            search_results_raw = search_books(
                effective_query,
                k=None,
                distance_threshold=1.0,
                exclude_rows=previous_row_ids  # âœ… exclude
            )

            search_results = filter_results_with_gpt(user_query, search_results_raw, last_query)

            # âœ… double-check for exclude
            search_results = [r for r in search_results if r['Ø±Ø¯ÙŠÙ'] not in previous_row_ids]

            if not search_results:
                return f"Ù…ØªØ£Ø³ÙÙ…ØŒ Ú©ØªØ§Ø¨ Ø¬Ø¯ÛŒØ¯ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯Ù…. ğŸ˜”\n\nâœ… Ù‚Ø¨Ù„Ø§Ù‹ {len(shown_results)} Ú©ØªØ§Ø¨ Ù…Ø¹Ø±ÙÛŒ Ú©Ø±Ø¯Ù…."

            save_search_results(chat_id, search_results, last_query)
            is_followup = False
        else:
            search_results = filter_results_with_gpt(user_query, prev_results, last_query)
            if not search_results:
                search_results = prev_results[:5]

    elif not author_search_done:
        # New search
        print(f"ğŸ” Search: {user_query}")

        search_results_raw = search_books(user_query, k=None, distance_threshold=0.8)

        if not search_results_raw:
            search_results_raw = search_books(user_query, k=None, distance_threshold=1.4)

        if not search_results_raw:
            return "Ù…ØªØ£Ø³ÙÙ…ØŒ Ú©ØªØ§Ø¨ Ù…Ø±ØªØ¨Ø·ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯Ù…. ğŸ˜”"

        search_results = filter_results_with_gpt(user_query, search_results_raw, user_query)

        if not search_results:
            search_results = search_results_raw[:6]

        search_results = search_results[:10]
        save_search_results(chat_id, search_results, user_query)

        last_shown_results[chat_id] = search_results[:6]

        print(f"ğŸ’¾ Save {len(search_results[:6])} Book:")
        for i, book in enumerate(search_results[:6], 1):
            print(f"   {i}. Â«{book['Ø¹Ù†ÙˆØ§Ù†'][:40]}...Â»")

    # Create context and send to GPT (no changes)

    # Create context for GPT
    context_parts = []
    for r in search_results:
        context_parts.append(f"Â«{r['Ø¹Ù†ÙˆØ§Ù†']}Â» â€” {r['Ù¾Ø¯ÙŠØ¯Ø¢ÙˆØ±Ù†Ø¯Ù‡']}, {r['Ù†Ø§Ø´Ø±']}")
    context = "\n".join(context_parts)

    history = get_conversation_history(chat_id, limit=10)
    messages = [{"role": "system", "content": config.SYSTEM_PROMPT}]
    for h in history:
        messages.append({"role": h["role"], "content": h["content"][:500]})

    user_message = f"Ú©ØªØ§Ø¨â€ŒÙ‡Ø§:\n{context}\n\nØ³ÙˆØ§Ù„: {user_query}"
    messages.append({"role": "user", "content": user_message})

    try:
        response = openai_client.chat.completions.create(
            model=config.GPT_MODEL,
            messages=messages,
            max_tokens=1500,
            temperature=0.1
        )
        assistant_response_raw = response.choices[0].message.content

        assistant_response = format_book_output(assistant_response_raw, search_results)

        mentioned_titles = re.findall(r'ğŸ”¹ Â«([^Â»]+)Â»', assistant_response)

        if mentioned_titles:
            def normalize_title(title):
                return re.sub(r'\s+', ' ', title.replace('\u200c', ' ').strip())

            shown_books = []
            used_indices = set()

            for title in mentioned_titles:
                title_norm = normalize_title(title)
                for idx, book in enumerate(search_results):
                    if idx in used_indices:
                        continue
                    book_title_norm = normalize_title(book.get('Ø¹Ù†ÙˆØ§Ù†', ''))
                    if book_title_norm == title_norm:
                        shown_books.append(book)
                        used_indices.add(idx)
                        break

            if shown_books:
                last_shown_results[chat_id] = shown_books

                print(f"\nğŸ’¾ Update shown: {len(shown_books)} Book")
                for i, book in enumerate(shown_books, 1):
                    print(f"   {i}. Â«{book['Ø¹Ù†ÙˆØ§Ù†'][:40]}...Â»")

        add_to_conversation(chat_id, "user", user_query)
        add_to_conversation(chat_id, "assistant", assistant_response)
        return assistant_response

    except Exception as e:
        print(f"âŒ Error: {e}")
        return "Ù…ØªØ£Ø³ÙÙ…ØŒ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯."


# Telegram commands
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [["ğŸ“š Ø¬Ø³ØªØ¬ÙˆÛŒ Ú©ØªØ§Ø¨"], ["ğŸ“– Ø±Ø§Ù‡Ù†Ù…Ø§", "ğŸ”„ Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¬Ø¯ÛŒØ¯"]]
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
    welcome_message = (
        "Ø³Ù„Ø§Ù…! ğŸ‘‹\n\n"
        "Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯! ğŸ“š\n\n"
        "Ù…Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù…:\n"
        "âœ… Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø±Ø§ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¯Ù‡Ù…\n"
        "âœ… Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ù¾ÛŒâ€ŒØ¯Ø±Ù¾ÛŒ Ø´Ù…Ø§ Ù¾Ø§Ø³Ø® Ø¯Ù‡Ù… (ØªØ§ 3 Ø±ÙˆØ²)\n"
        "âœ… Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ Ø±Ø§ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ú©Ù†Ù…\n\n"
        "Ù…Ø«Ø§Ù„ Ù…Ú©Ø§Ù„Ù…Ù‡:\n"
        "Ø´Ù…Ø§: Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ù†ÛŒÙ…Ø§ ÛŒÙˆØ´ÛŒØ¬\n"
        "Ù…Ù†: [4 Ú©ØªØ§Ø¨ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯]\n"
        "Ø´Ù…Ø§: Ù…Ù† Ù…Ø¨ØªØ¯ÛŒÙ…ØŒ Ø¨Ù‡ØªØ±ÛŒÙ†Ø´ Ú©Ø¯ÙˆÙ…Ù‡ØŸ\n"
        "Ù…Ù†: [Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§Ø³Ø§Ø³ Ù‡Ù…ÙˆÙ† Ù†ØªØ§ÛŒØ¬]\n\n"
        "ğŸ’¡ Ø­Ø§ÙØ¸Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡: 3 Ø±ÙˆØ²\n"
        "ğŸ—‘ï¸ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±: Ø¨Ø¹Ø¯ Ø§Ø² 1 Ù‡ÙØªÙ‡\n\n"
        "Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¬Ø¯ÛŒØ¯: /new"
    )
    await update.message.reply_text(welcome_message, reply_markup=reply_markup)


async def new_conversation_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    conversation_memory.pop(chat_id, None)
    search_results_memory.pop(chat_id, None)
    last_query_memory.pop(chat_id, None)
    last_shown_results.pop(chat_id, None)
    await update.message.reply_text(
        "âœ… Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¬Ø¯ÛŒØ¯ Ø´Ø±ÙˆØ¹ Ø´Ø¯!\n\n"
        "Ø­Ø§Ù„Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø³ÙˆØ§Ù„ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¨Ù¾Ø±Ø³ÛŒØ¯. ğŸ˜Š"
    )


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_message = (
        "ğŸ“– **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡:**\n\n"
        "ğŸ”¹ Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯\n"
        "ğŸ”¹ Ø³ÙˆØ§Ù„Ø§Øª Ø¨Ø¹Ø¯ÛŒ Ø±Ø§ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù‡Ù…Ø§Ù† Ù†ØªØ§ÛŒØ¬ Ø¨Ù¾Ø±Ø³ÛŒØ¯\n"
        "ğŸ”¹ Ø¨Ø±Ø§ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¬Ø¯ÛŒØ¯: /new\n\n"
        "**Ù…Ø«Ø§Ù„:**\n"
        "â€¢ Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ù†ÛŒÙ…Ø§ ÛŒÙˆØ´ÛŒØ¬\n"
        "â€¢ Ù…Ù† Ù…Ø¨ØªØ¯ÛŒÙ…ØŒ Ú©Ø¯ÙˆÙ… Ø±Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒØ¯ÛŒØŸ\n"
        "â€¢ Ú©Ø¯ÙˆÙ… Ø¬Ø¯ÛŒØ¯ØªØ±Ù‡ØŸ\n"
        "â€¢ Ø¨ÛŒØ´ØªØ± Ø¨Ú¯Ùˆ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø§ÙˆÙ„ÛŒ"
    )
    await update.message.reply_text(help_message, parse_mode='Markdown')


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    chat_id = update.effective_chat.id

    if user_message == "ğŸ“š Ø¬Ø³ØªØ¬ÙˆÛŒ Ú©ØªØ§Ø¨":
        await update.message.reply_text("Ù„Ø·ÙØ§Ù‹ Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯")
        return
    elif user_message == "ğŸ“– Ø±Ø§Ù‡Ù†Ù…Ø§":
        await help_command(update, context)
        return
    elif user_message == "ğŸ”„ Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¬Ø¯ÛŒØ¯":
        await new_conversation_command(update, context)
        return

    await update.message.chat.send_action(action="typing")
    response = generate_rag_response(user_message, chat_id)
    await update.message.reply_text(response)


def main():
    print("="*60)
    print("ğŸ¤– Launching the bot")
    print("="*60)

    if not initialize_embedder():
        print("âŒ Error in setup!")
        return

    TELEGRAM_BOT_TOKEN = "YOUR_TELEGRAM_BOT_TOKEN_HERE"
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(CommandHandler("new", new_conversation_command))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    print("âœ… Bot is ready!")
    print("="*60)

    app.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ Bot stopped")
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
