import pandas as pd
import re
from typing import Optional


class ThesisNormalizer:

    def __init__(self):
        pass

    def clean_text(self, text: str) -> str:
        if pd.isna(text) or text is None:
            return ""

        text = str(text).strip()

        # Remove extra spacing
        text = re.sub(r'\s+', ' ', text)

        # Remove special characters
        text = text.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')

        return text.strip()

    def extract_year(self, date_text: str) -> Optional[str]:
        if pd.isna(date_text):
            return None

        date_text = str(date_text).strip()

        match = re.search(r'(\d{4})', date_text)
        if match:
            year = match.group(1)
            if 1300 <= int(year) <= 1420:
                return year

        return None

    def normalize_professor_name(self, name: str) -> str:
        if pd.isna(name) or name is None:
            return ""

        name = str(name).strip()

        name = name.replace('/', '').strip()

        name = re.sub(r'\s+', ' ', name)

        return name.strip()

    def clean_keywords(self, keywords: str) -> str:
        if pd.isna(keywords):
            return ""

        keywords = str(keywords).strip()

        keywords = keywords.replace('ุ', 'ุ').replace(';', 'ุ').replace('-', 'ุ')

        keywords = self.clean_text(keywords)

        return keywords

    def normalize(self, df: pd.DataFrame) -> pd.DataFrame:

        print("\n๐งน Starting data cleaning...")
        print("=" * 70)

        df_clean = df.copy()

        column_mapping = {
            'ุนููุงู': 'ุนููุงู ูพุงุงูโูุงูู',
            'ูพฺููุดฺฏุฑ': 'ููุณูุฏู',
            'ููุทุน': 'ููุทุน',
            'ุฑุดุชู ุชุญุตููู': 'ุฑุดุชู',
            'ุงุณุชุงุฏ ุฑุงูููุง': 'ุงุณุชุงุฏ ุฑุงูููุง',
            'ุงุณุชุงุฏ ูุดุงูุฑ': 'ุงุณุชุงุฏ ูุดุงูุฑ',
            'ุชูุตููฺฏุฑ': 'ฺฉูุฏูุงฺูโูุง',
            'ุชุงุฑูุฎ ุฏูุงุน': 'ุชุงุฑุฎ ุฏูุงุน',
            'ุฑุฏูู': 'ุฑุฏูู'
        }

        df_clean = df_clean.rename(columns=column_mapping)

        print("๐น Cleaning title...")
        if 'ุนููุงู ูพุงุงูโูุงูู' in df_clean.columns:
            df_clean['ุนููุงู ูพุงุงูโูุงูู'] = df_clean['ุนููุงู ูพุงุงูโูุงูู'].apply(self.clean_text)

        print("๐น Cleaning author...")
        if 'ููุณูุฏู' in df_clean.columns:
            df_clean['ููุณูุฏู'] = df_clean['ููุณูุฏู'].apply(self.clean_text)

        print("๐น Cleaning degree...")
        if 'ููุทุน' in df_clean.columns:
            df_clean['ููุทุน'] = df_clean['ููุทุน'].apply(self.clean_text)

        print("๐น Cleaning major...")
        if 'ุฑุดุชู' in df_clean.columns:
            df_clean['ุฑุดุชู'] = df_clean['ุฑุดุชู'].apply(self.clean_text)

        print("๐น Normalizing advisor name...")
        if 'ุงุณุชุงุฏ ุฑุงูููุง' in df_clean.columns:
            df_clean['ุงุณุชุงุฏ ุฑุงูููุง'] = df_clean['ุงุณุชุงุฏ ุฑุงูููุง'].apply(self.normalize_professor_name)

        print("๐น Normalizing co-advisor name...")
        if 'ุงุณุชุงุฏ ูุดุงูุฑ' in df_clean.columns:
            df_clean['ุงุณุชุงุฏ ูุดุงูุฑ'] = df_clean['ุงุณุชุงุฏ ูุดุงูุฑ'].apply(self.normalize_professor_name)

        print("๐น Cleaning keywords...")
        if 'ฺฉูุฏูุงฺูโูุง' in df_clean.columns:
            df_clean['ฺฉูุฏูุงฺูโูุง'] = df_clean['ฺฉูุฏูุงฺูโูุง'].apply(self.clean_keywords)

        print("๐น Extracting year...")
        if 'ุชุงุฑุฎ ุฏูุงุน' in df_clean.columns:
            df_clean['ุณุงู ุฏูุงุน'] = df_clean['ุชุงุฑุฎ ุฏูุงุน'].apply(self.extract_year)

        if 'ุฏุงูุดฺฉุฏู' not in df_clean.columns:
            df_clean['ุฏุงูุดฺฉุฏู'] = ""

        print("๐น Removing empty title rows...")
        initial_count = len(df_clean)
        df_clean = df_clean[df_clean['ุนููุงู ูพุงุงูโูุงูู'].str.strip() != ""]
        removed_count = initial_count - len(df_clean)
        print(f" โ Removed {removed_count} empty rows")

        print("๐น Creating combined search text...")
        df_clean['ูุชู_ุฌุณุชุฌู'] = df_clean.apply(self._create_search_text, axis=1)

        columns_order = [
            'ุฑุฏูู',
            'ุนููุงู ูพุงุงูโูุงูู',
            'ููุณูุฏู',
            'ููุทุน',
            'ุฑุดุชู',
            'ุงุณุชุงุฏ ุฑุงูููุง',
            'ุงุณุชุงุฏ ูุดุงูุฑ',
            'ุฏุงูุดฺฉุฏู',
            'ุณุงู ุฏูุงุน',
            'ฺฉูุฏูุงฺูโูุง',
            'ุชุงุฑุฎ ุฏูุงุน',
            'ูุชู_ุฌุณุชุฌู'
        ]

        existing_columns = [col for col in columns_order if col in df_clean.columns]
        df_clean = df_clean[existing_columns]

        print("=" * 70)
        print(f"โ Normalization complete: {len(df_clean)} theses")

        return df_clean

    def _create_search_text(self, row) -> str:
        parts = []

        if pd.notna(row.get('ุนููุงู ูพุงุงูโูุงูู')):
            parts.append(str(row['ุนููุงู ูพุงุงูโูุงูู']))

        if pd.notna(row.get('ููุณูุฏู')):
            parts.append(f"ููุณูุฏู: {row['ููุณูุฏู']}")

        if pd.notna(row.get('ุงุณุชุงุฏ ุฑุงูููุง')):
            parts.append(f"ุฑุงูููุง: {row['ุงุณุชุงุฏ ุฑุงูููุง']}")

        if pd.notna(row.get('ุงุณุชุงุฏ ูุดุงูุฑ')):
            parts.append(f"ูุดุงูุฑ: {row['ุงุณุชุงุฏ ูุดุงูุฑ']}")

        if pd.notna(row.get('ุฑุดุชู')):
            parts.append(f"ุฑุดุชู: {row['ุฑุดุชู']}")

        if pd.notna(row.get('ููุทุน')):
            parts.append(f"ููุทุน: {row['ููุทุน']}")

        if pd.notna(row.get('ุฏุงูุดฺฉุฏู')):
            parts.append(f"ุฏุงูุดฺฉุฏู: {row['ุฏุงูุดฺฉุฏู']}")

        if pd.notna(row.get('ุณุงู ุฏูุงุน')):
            parts.append(f"ุณุงู: {row['ุณุงู ุฏูุงุน']}")

        if pd.notna(row.get('ฺฉูุฏูุงฺูโูุง')):
            parts.append(f"ฺฉูุฏูุงฺู: {row['ฺฉูุฏูุงฺูโูุง']}")

        return " | ".join(parts)


if __name__ == "__main__":

    print("=" * 70)
    print("๐ Thesis Normalizer Test")
    print("=" * 70)

    sample_data = {
        'ุนููุงู': ['ุจุฑุฑุณ ุงูฺฏูุฑุชูโูุง ุงุฏฺฏุฑ ูุงุดู', 'ูุทุงูุนู ุดุจฺฉูโูุง ุนุตุจ'],
        'ูพฺููุดฺฏุฑ': ['ุนู ุงุญูุฏ', 'ุฒูุฑุง ูุญูุฏ'],
        'ููุทุน': ['ฺฉุงุฑุดูุงุณ ุงุฑุดุฏ', 'ุฏฺฉุชุฑ'],
        'ุฑุดุชู ุชุญุตููู': ['ุนููู ฺฉุงููพูุชุฑ', 'ููุด ูุตููุน'],
        'ุงุณุชุงุฏ ุฑุงูููุง': ['/ ุฏฺฉุชุฑ ุฑุถุง', '/ ุฏฺฉุชุฑ ฺฉุฑู'],
        'ุงุณุชุงุฏ ูุดุงูุฑ': ['/ ุฏฺฉุชุฑ ููุฑ', ''],
        'ุชูุตููฺฏุฑ': ['ุงุฏฺฏุฑ ูุงุดู - ุงูฺฏูุฑุชู', 'ุดุจฺฉู ุนุตุจ - deep learning'],
        'ุชุงุฑูุฎ ุฏูุงุน': ['1402/05/15', '1401/09/20'],
        'ุฑุฏูู': [1, 2]
    }

    df = pd.DataFrame(sample_data)

    print("\n๐ Data:")
    print(df)

    normalizer = ThesisNormalizer()
    df_normalized = normalizer.normalize(df)

    print("\nโจ Normalized data:")
    print(df_normalized[['ุนููุงู ูพุงุงูโูุงูู', 'ููุณูุฏู', 'ุณุงู ุฏูุงุน', 'ุงุณุชุงุฏ ุฑุงูููุง']])

    print("\nโ Test complete!")
